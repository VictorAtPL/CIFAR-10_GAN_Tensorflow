{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google_Colab_Train_eval_predict.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Twp4qUjppylV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VARIABLES WHICH MUST BE SET\n",
        "BUCKET_NAME = \"\" # please do create that Storage Bucket on Google Cloud Platform and make it public, so no additional permissions are required\n",
        "ARCHITECTURE = \"dcgan\" # either \"mlpgan\" or \"dcgan\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IiArbGM0XySX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip -q install tensorflow-gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IVVLtFT1D8AL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline  \n",
        "import numpy as np\n",
        "import os\n",
        "import pprint\n",
        "from PIL import Image\n",
        "import re\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "import tensorflow_gan as tfgan\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "DATASET_SIZE = 60000\n",
        "TRAIN_BATCH_SIZE_PER_TPU = 128\n",
        "TPU_CORES = 8\n",
        "PREDICT_BATCH_SIZE = 64\n",
        "\n",
        "TRAIN_BATCH_SIZE = TRAIN_BATCH_SIZE_PER_TPU * TPU_CORES # 128 examples per tpu core, 8 tpu cores, so 1024 examples overall\n",
        "\n",
        "TRAIN_SET_SIZE = DATASET_SIZE // TRAIN_BATCH_SIZE * TRAIN_BATCH_SIZE\n",
        "assert TRAIN_SET_SIZE < 60000, \"Train set size can't be bigger than whole dataset\"\n",
        "\n",
        "EVAL_BATCH_SIZE = TRAIN_SET_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qcn6e0iP7EEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Dataset size: {}\".format(DATASET_SIZE))\n",
        "print(\"Train set size: {}\".format(TRAIN_SET_SIZE))\n",
        "print(\"Train batch size: {}\".format(TRAIN_BATCH_SIZE))\n",
        "print(\"Test set size: {}\".format(TRAIN_SET_SIZE))\n",
        "print(\"Eval batch size: {}\".format(EVAL_BATCH_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vD1SjRABR633",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D1qksxUorR88",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_cifar_tfrecords():\n",
        "  if tf.gfile.Exists(\"gs://{}/tfrecords\".format(BUCKET_NAME)):\n",
        "    tf.gfile.DeleteRecursively(\"gs://{}/tfrecords\".format(BUCKET_NAME))\n",
        "\n",
        "  dataset = tf.keras.datasets.cifar10.load_data()\n",
        "  x = np.concatenate([dataset[0][0], dataset[1][0]], axis=0)\n",
        "  y = np.concatenate([dataset[0][1], dataset[1][1]], axis=0)\n",
        "\n",
        "  np.random.seed(0)\n",
        "  indices_permutated = np.random.permutation(x.shape[0])\n",
        "\n",
        "  x = np.take(x, indices_permutated[:TRAIN_SET_SIZE], axis=0)\n",
        "  y = np.take(y, indices_permutated[:TRAIN_SET_SIZE], axis=0)\n",
        "\n",
        "  def convert_mnist_to_tfrecords(output_path, file_pattern, x, y, number_of_shards = 1):\n",
        "    assert x.shape[0] == y.shape[0], \"Number of examples in x and y must be equal.\"\n",
        "\n",
        "    if not os.path.exists(output_path):\n",
        "      os.makedirs(output_path)\n",
        "\n",
        "    examples_no = x.shape[0]\n",
        "\n",
        "    x_train_chunks = np.split(x, number_of_shards)\n",
        "    y_train_chunks = np.split(y, number_of_shards)\n",
        "\n",
        "    for i, (x_train, y_train) in enumerate(zip(x_train_chunks, y_train_chunks)):\n",
        "      with tf.python_io.TFRecordWriter(os.path.join(output_path, file_pattern.format(i + 1, number_of_shards))) as writer:\n",
        "        for image, label_id in zip(x_train, y_train):\n",
        "          example = tf.train.Example(features=tf.train.Features(feature={'image': tf.train.Feature(int64_list=tf.train.Int64List(value=image.flatten())),\n",
        "                                                                         'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label_id]))}))\n",
        "\n",
        "          writer.write(example.SerializeToString())\n",
        "\n",
        "  convert_mnist_to_tfrecords('gs://{}/tfrecords'.format(BUCKET_NAME), 'train-{}-of-{}.tfrecords', x, y, number_of_shards=2)\n",
        "  \n",
        "generate_cifar_tfrecords()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WyD9RllH13DM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "r = requests.get('https://storage.googleapis.com/{}/'.format(BUCKET_NAME))\n",
        "root = ET.fromstring(r.content)\n",
        "bucket_files = [contents_key.text for contents_key in root.findall('{http://doc.s3.amazonaws.com/2006-03-01}Contents/{http://doc.s3.amazonaws.com/2006-03-01}Key')]\n",
        "\n",
        "train_tfrecord_files = [\"gs://{}/{}\".format(BUCKET_NAME, item) for item in bucket_files if re.search(re.escape(\"tfrecords/train-*-of-*.tfrecords\").replace(\"\\\\*\", \"[0-9]+\"), item)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "844SpDRfdw96",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -q -O ngrok-stable-linux-amd64.zip https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -q -o ngrok-stable-linux-amd64.zip -d ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "py_nUmpLX-uj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = \"gs://{}/models_dir/experiments_mlpgan_17042019_151813\".format(BUCKET_NAME)\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pg3fvSMhZV3x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JN1h50N6rkYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_input_with_noise_fn(filenames, shuffle=False):\n",
        "\n",
        "  def input_fn_with_noise(params):\n",
        "    batch_size = params[\"batch_size\"]\n",
        "    noise_dim = params[\"noise_dim\"]\n",
        "\n",
        "    def parser(serialized_example):\n",
        "      features = tf.parse_single_example(\n",
        "          serialized_example,\n",
        "          features={\n",
        "              \"image\": tf.FixedLenFeature([32, 32, 3], tf.int64),\n",
        "              \"label\": tf.FixedLenFeature([], tf.int64),\n",
        "          })\n",
        "      \n",
        "      image = tf.cast(features[\"image\"], tf.float32) * (2. / 255) - 1\n",
        "      \n",
        "      return image\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames)\n",
        "    dataset = dataset.map(parser, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.repeat()\n",
        "    \n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
        "    \n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    images = dataset.make_one_shot_iterator().get_next()    \n",
        "    random_noise = tf.random_normal([batch_size, noise_dim], dtype=tf.float32)\n",
        "    \n",
        "    return random_noise, images\n",
        "\n",
        "  return input_fn_with_noise\n",
        "\n",
        "def noise_input_fn(params):\n",
        "  batch_size = params[\"batch_size\"]\n",
        "  noise_dim = params[\"noise_dim\"]\n",
        "    \n",
        "  np.random.seed(0)\n",
        "  return tf.data.Dataset.from_tensors(tf.constant(\n",
        "      np.random.randn(batch_size, noise_dim), dtype=tf.float32))\n",
        "\n",
        "train_input_with_noise_fn = make_input_with_noise_fn(train_tfrecord_files, shuffle=True)\n",
        "test_input_with_noise_fn = make_input_with_noise_fn(train_tfrecord_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hHASJ-j0QBVZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _leaky_relu(x):\n",
        "  return tf.nn.leaky_relu(x, alpha=0.2)\n",
        "\n",
        "def _relu(x):\n",
        "  return tf.nn.relu(x)\n",
        "\n",
        "def _tanh(x):\n",
        "  return tf.tanh(x)\n",
        "\n",
        "def _batch_norm(x, is_training, name):\n",
        "  return tf.layers.batch_normalization(\n",
        "      x, momentum=0.9, epsilon=1e-5, training=is_training, name=name)\n",
        "\n",
        "\n",
        "def _dense(x, channels, name):\n",
        "  return tf.layers.dense(\n",
        "      x, channels,\n",
        "      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "      name=name)\n",
        "\n",
        "\n",
        "def _conv2d(x, filters, kernel_size, stride, name):\n",
        "  return tf.layers.conv2d(\n",
        "      x, filters, [kernel_size, kernel_size],\n",
        "      strides=[stride, stride], padding='same',\n",
        "      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "      name=name)\n",
        "\n",
        "\n",
        "def _deconv2d(x, filters, kernel_size, stride, name):\n",
        "  return tf.layers.conv2d_transpose(\n",
        "      x, filters, [kernel_size, kernel_size],\n",
        "      strides=[stride, stride], padding='same',\n",
        "      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "      name=name)\n",
        "\n",
        "def _flatten(x):\n",
        "  return tf.layers.flatten(x)\n",
        "\n",
        "def _dropout(x, is_training):\n",
        "  return tf.layers.dropout(x, rate=0.25, training=is_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hitMDaRWrJuf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MLPGAN\n",
        "def mlpgan_discriminator_fn(images, unused_conditioning, mode):\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  \n",
        "  with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE):\n",
        "    x = _flatten(images)\n",
        "    \n",
        "    x = _dense(x, 256, 'd_fc1')\n",
        "    x = _dropout(x, is_training)\n",
        "    x = _tanh(x)\n",
        "\n",
        "    x = _dense(x, 1, 'd_fc2')\n",
        "    \n",
        "  return x\n",
        "\n",
        "def mlpgan_generator_fn(random_noise, mode):\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  \n",
        "  with tf.variable_scope('generator', reuse=tf.AUTO_REUSE):\n",
        "    x = _dense(random_noise, 256, 'g_fc1')\n",
        "    x = _dropout(x, is_training)\n",
        "    x = _tanh(x)\n",
        "    \n",
        "    x = _dense(x, 32 * 32 * 3, 'g_fc2')\n",
        "\n",
        "    x = tf.reshape(x, [-1, 32, 32, 3])\n",
        "    x = _tanh(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4wvL4_srHwW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DCGAN\n",
        "def dcgan_discriminator_fn(images, unused_conditioning, mode):\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  \n",
        "  with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE):\n",
        "    x = _conv2d(images, 64, 5, 2, 'd_conv1')\n",
        "    x = _leaky_relu(x)\n",
        "\n",
        "    x = _conv2d(x, 128, 5, 2, 'd_conv2')\n",
        "    x = _batch_norm(x, is_training, 'd_bn2')\n",
        "    x = _leaky_relu(x)\n",
        "    \n",
        "    x = _conv2d(x, 256, 5, 2, 'd_conv3')\n",
        "    x = _batch_norm(x, is_training, 'd_bn3')\n",
        "    x = _leaky_relu(x)\n",
        "\n",
        "    x = tf.reshape(x, [-1, 4 * 4 * 256])\n",
        "\n",
        "    x = _dense(x, 1, 'd_fc4')\n",
        "    \n",
        "  return x\n",
        "\n",
        "def dcgan_generator_fn(random_noise, mode):\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  \n",
        "  with tf.variable_scope('generator', reuse=tf.AUTO_REUSE):\n",
        "    x = _dense(random_noise, 4096, 'g_fc1')\n",
        "    x = _batch_norm(x, is_training, 'g_bn1')\n",
        "    x = _relu(x)\n",
        "\n",
        "    x = tf.reshape(x, [-1, 4, 4, 256])\n",
        "\n",
        "    x = _deconv2d(x, 128, 5, 2, 'g_dconv2')\n",
        "    x = _batch_norm(x, is_training, 'g_bn2')\n",
        "    x = _relu(x)\n",
        "    \n",
        "    x = _deconv2d(x, 64, 4, 2, 'g_dconv3')\n",
        "    x = _batch_norm(x, is_training, 'g_bn3')\n",
        "    x = _relu(x)\n",
        "\n",
        "    x = _deconv2d(x, 3, 4, 2, 'g_dconv4')\n",
        "    x = _tanh(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBMcNGEqpBKQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "architectures = {\n",
        "    \"mlpgan\": {\n",
        "        \"generator_fn\": mlpgan_generator_fn,\n",
        "        \"discriminator_fn\": mlpgan_discriminator_fn,\n",
        "        \"generator_loss_fn\": tfgan.losses.modified_generator_loss,\n",
        "        \"discriminator_loss_fn\": tfgan.losses.modified_discriminator_loss,\n",
        "        \"generator_optimizer\": tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        \"discriminator_optimizer\": tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        \"estimator_class\": tfgan.estimator.TPUGANEstimator,\n",
        "        \"noise_dim\": 128\n",
        "    },\n",
        "    \"dcgan\": {\n",
        "        \"generator_fn\": dcgan_generator_fn,\n",
        "        \"discriminator_fn\": dcgan_discriminator_fn,\n",
        "        \"generator_loss_fn\": tfgan.losses.modified_generator_loss,\n",
        "        \"discriminator_loss_fn\": tfgan.losses.modified_discriminator_loss,\n",
        "        \"generator_optimizer\": tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        \"discriminator_optimizer\": tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        \"estimator_class\": tfgan.estimator.TPUGANEstimator,\n",
        "        \"noise_dim\": 128\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XoJiZ_BtqkXF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if ARCHITECTURE not in architectures.keys():\n",
        "  print(\"Architecture {} not found\".format(ARCHITECTURE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FrMG1L2wgrL2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "time = datetime.now().strftime('%d%m%Y_%H%M%S')\n",
        "\n",
        "cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver()\n",
        "master = cluster_resolver.get_master()\n",
        "  \n",
        "model_name = \"experiments_{}_{}\".format(ARCHITECTURE, time)\n",
        "model_dir = \"gs://{}/models_dir/{}\".format(BUCKET_NAME, model_name)\n",
        "\n",
        "batches_per_epoch = int(TRAIN_SET_SIZE / TRAIN_BATCH_SIZE)\n",
        "steps_per_epoch = int(batches_per_epoch) * 2\n",
        "iterations_per_loop = int(batches_per_epoch) * 2 # 2 epochs per iteration\n",
        "iterations_steps = iterations_per_loop\n",
        "\n",
        "my_tpu_run_config = tf.contrib.tpu.RunConfig(\n",
        "    master=master,\n",
        "    evaluation_master=master,\n",
        "    model_dir=model_dir,\n",
        "    session_config=tf.ConfigProto(\n",
        "        allow_soft_placement=True,\n",
        "        log_device_placement=True),\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=iterations_per_loop),\n",
        "    save_summary_steps=batches_per_epoch, # save summary every TPU iteration\n",
        "    save_checkpoints_steps=None, # see below\n",
        "    save_checkpoints_secs=3600, # save checkpoints every one hour\n",
        "    keep_checkpoint_max=None        \n",
        ") \n",
        "\n",
        "selected_architecture_config = architectures[ARCHITECTURE]\n",
        "my_gan_estimator = selected_architecture_config['estimator_class'](\n",
        "  generator_fn=selected_architecture_config['generator_fn'],\n",
        "  discriminator_fn=selected_architecture_config['discriminator_fn'],\n",
        "  generator_loss_fn=selected_architecture_config['generator_loss_fn'],\n",
        "  discriminator_loss_fn=selected_architecture_config['discriminator_loss_fn'],\n",
        "  generator_optimizer=selected_architecture_config['generator_optimizer'],\n",
        "  discriminator_optimizer=selected_architecture_config['discriminator_optimizer'],\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  joint_train=False,\n",
        "  config=my_tpu_run_config,\n",
        "  use_tpu=True,\n",
        "  params={\"noise_dim\": selected_architecture_config['noise_dim']},\n",
        "  # EVAL\n",
        "  eval_on_tpu=True,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  # PREDICT\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yxJhuH-8Yz8t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PREVIEW = False\n",
        "\n",
        "epochs_total = 1000\n",
        "\n",
        "# create dir for generated images\n",
        "tf.gfile.MakeDirs(os.path.join(model_dir, \"generated_images\"))\n",
        "\n",
        "# eval_predict_epochs = [] # predict only after epochs_total\n",
        "eval_predict_epochs = [10, 20, 50, 100, 200, 400, 500, 600, 700, 800, 900] # predict every epochs listed on the left\n",
        "\n",
        "# add epochs_total\n",
        "eval_predict_epochs.append(epochs_total)\n",
        "\n",
        "if PREVIEW:\n",
        "  eval_predict_epochs = [epochs_total]\n",
        "\n",
        "dpi = 80.0\n",
        "stop = False\n",
        "for to_epoch in eval_predict_epochs:\n",
        "  if to_epoch >= epochs_total:\n",
        "    to_epoch = epochs_total\n",
        "    stop = True\n",
        "    \n",
        "  my_gan_estimator.train(train_input_with_noise_fn, max_steps=to_epoch * steps_per_epoch)\n",
        "  \n",
        "  if not PREVIEW:\n",
        "    evaluate_ret = my_gan_estimator.evaluate(test_input_with_noise_fn, steps=1)\n",
        "    evaluate_ret['epoch'] = int(evaluate_ret['global_step'] / float(steps_per_epoch))\n",
        "    print(evaluate_ret)\n",
        "  \n",
        "  generated_iter = my_gan_estimator.predict(input_fn=noise_input_fn)\n",
        "  images = [((p['generated_data'][:, :, :] + 1.0) / 2.0) for p in generated_iter]\n",
        "  assert len(images) == PREDICT_BATCH_SIZE\n",
        "  image_rows = [np.concatenate(images[i:i+8], axis=0)\n",
        "                for i in range(0, PREDICT_BATCH_SIZE, 8)]\n",
        "  tiled_image = np.concatenate(image_rows, axis=1)\n",
        "  \n",
        "  shape = tiled_image.shape\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(shape[1]/float(dpi), shape[0]/float(dpi)), dpi=dpi, frameon=False)\n",
        "  ax.imshow(tiled_image, extent=(0, 1, 1 ,0))\n",
        "  ax.set_xticks([])  # remove xticks\n",
        "  ax.set_yticks([])  # remove yticks\n",
        "  ax.axis('off')     # hide axis\n",
        "  fig.subplots_adjust(bottom=0, top=1, left=0, right=1, wspace=0, hspace=0)  # streches the image and removes margins\n",
        "  plt.show()\n",
        "  \n",
        "  if not PREVIEW:\n",
        "    step_string = str(to_epoch).zfill(5)\n",
        "    file_obj = tf.gfile.Open(os.path.join(model_dir, \"generated_images\", \"{}.jpeg\".format(step_string)), 'w')\n",
        "    fig.savefig(file_obj, quality=100, dpi=int(dpi))\n",
        "    plt.close(fig)\n",
        "    file_obj.close()\n",
        "  else:\n",
        "    tf.gfile.DeleteRecursively(model_dir)\n",
        "  \n",
        "  if stop:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}