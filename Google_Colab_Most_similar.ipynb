{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google_Colab_Most_similar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "SHthOQ4OrG5C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# VARIABLES WHICH MUST BE SET\n",
        "BUCKET_NAME = \"\" # please do create that Storage Bucket on Google Cloud Platform and make it public, so no additional permissions are required\n",
        "ARCHITECTURE = \"dcgan\" # either \"mlpgan\" or \"dcgan\"\n",
        "model_name = \"experiments_dcgan_17042019_142218\" # model directory name from you BUCKET_NAME/models_dir directory\n",
        "from_step = 116000 # from which step checkpoint should be use in prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IiArbGM0XySX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip -q install tensorflow-gan scikit-image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IVVLtFT1D8AL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline  \n",
        "import numpy as np\n",
        "import os\n",
        "import pprint\n",
        "from PIL import Image\n",
        "import re\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "import tensorflow_gan as tfgan\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "DATASET_SIZE = 60000\n",
        "TRAIN_BATCH_SIZE_PER_TPU = 128\n",
        "TPU_CORES = 8\n",
        "PREDICT_BATCH_SIZE = 128\n",
        "\n",
        "TRAIN_BATCH_SIZE = TRAIN_BATCH_SIZE_PER_TPU * TPU_CORES # 128 examples per tpu core, 8 tpu cores, so 1024 examples overall\n",
        "\n",
        "TRAIN_SET_SIZE = DATASET_SIZE // TRAIN_BATCH_SIZE * TRAIN_BATCH_SIZE\n",
        "assert TRAIN_SET_SIZE < 60000, \"Train set size can't be bigger than whole dataset\"\n",
        "\n",
        "EVAL_BATCH_SIZE = TRAIN_SET_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qcn6e0iP7EEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Dataset size: {}\".format(DATASET_SIZE))\n",
        "print(\"Train set size: {}\".format(TRAIN_SET_SIZE))\n",
        "print(\"Train batch size: {}\".format(TRAIN_BATCH_SIZE))\n",
        "print(\"Test set size: {}\".format(TRAIN_SET_SIZE))\n",
        "print(\"Eval batch size: {}\".format(EVAL_BATCH_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vD1SjRABR633",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pmOgP8ihIx4T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.datasets.cifar10.load_data()\n",
        "x = np.concatenate([dataset[0][0], dataset[1][0]], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JN1h50N6rkYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def noise_input_fn(params):\n",
        "  batch_size = params[\"batch_size\"]\n",
        "  noise_dim = params[\"noise_dim\"]\n",
        "    \n",
        "  np.random.seed(0)\n",
        "  return tf.data.Dataset.from_tensors(tf.constant(\n",
        "      np.random.randn(batch_size, noise_dim), dtype=tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hHASJ-j0QBVZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _leaky_relu(x):\n",
        "  return tf.nn.leaky_relu(x, alpha=0.2)\n",
        "\n",
        "def _relu(x):\n",
        "  return tf.nn.relu(x)\n",
        "\n",
        "def _tanh(x):\n",
        "  return tf.tanh(x)\n",
        "\n",
        "def _batch_norm(x, is_training, name):\n",
        "  return tf.layers.batch_normalization(\n",
        "      x, momentum=0.9, epsilon=1e-5, training=is_training, name=name)\n",
        "\n",
        "\n",
        "def _dense(x, channels, name):\n",
        "  return tf.layers.dense(\n",
        "      x, channels,\n",
        "      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "      name=name)\n",
        "\n",
        "\n",
        "def _conv2d(x, filters, kernel_size, stride, name):\n",
        "  return tf.layers.conv2d(\n",
        "      x, filters, [kernel_size, kernel_size],\n",
        "      strides=[stride, stride], padding='same',\n",
        "      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "      name=name)\n",
        "\n",
        "\n",
        "def _deconv2d(x, filters, kernel_size, stride, name):\n",
        "  return tf.layers.conv2d_transpose(\n",
        "      x, filters, [kernel_size, kernel_size],\n",
        "      strides=[stride, stride], padding='same',\n",
        "      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
        "      name=name)\n",
        "\n",
        "def _flatten(x):\n",
        "  return tf.layers.flatten(x)\n",
        "\n",
        "def _dropout(x, is_training):\n",
        "  return tf.layers.dropout(x, rate=0.25, training=is_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-tzveVmLrWEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MLPGAN\n",
        "def mlpgan_discriminator_fn(images, unused_conditioning, mode):\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  \n",
        "  with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE):\n",
        "    x = _flatten(images)\n",
        "    \n",
        "    x = _dense(x, 256, 'd_fc1')\n",
        "    x = _dropout(x, is_training)\n",
        "    x = _tanh(x)\n",
        "\n",
        "    x = _dense(x, 1, 'd_fc2')\n",
        "    \n",
        "  return x\n",
        "\n",
        "def mlpgan_generator_fn(random_noise, mode):\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  \n",
        "  with tf.variable_scope('generator', reuse=tf.AUTO_REUSE):\n",
        "    x = _dense(random_noise, 256, 'g_fc1')\n",
        "    x = _dropout(x, is_training)\n",
        "    x = _tanh(x)\n",
        "    \n",
        "    x = _dense(x, 32 * 32 * 3, 'g_fc2')\n",
        "\n",
        "    x = tf.reshape(x, [-1, 32, 32, 3])\n",
        "    x = _tanh(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4wvL4_srHwW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DCGAN\n",
        "def dcgan_discriminator_fn(images, unused_conditioning, mode):\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  \n",
        "  with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE):\n",
        "    x = _conv2d(images, 64, 5, 2, 'd_conv1')\n",
        "    x = _leaky_relu(x)\n",
        "\n",
        "    x = _conv2d(x, 128, 5, 2, 'd_conv2')\n",
        "    x = _batch_norm(x, is_training, 'd_bn2')\n",
        "    x = _leaky_relu(x)\n",
        "    \n",
        "    x = _conv2d(x, 256, 5, 2, 'd_conv3')\n",
        "    x = _batch_norm(x, is_training, 'd_bn3')\n",
        "    x = _leaky_relu(x)\n",
        "\n",
        "    x = tf.reshape(x, [-1, 4 * 4 * 256])\n",
        "\n",
        "    x = _dense(x, 1, 'd_fc4')\n",
        "    \n",
        "  return x\n",
        "\n",
        "def dcgan_generator_fn(random_noise, mode):\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  \n",
        "  with tf.variable_scope('generator', reuse=tf.AUTO_REUSE):\n",
        "    x = _dense(random_noise, 4096, 'g_fc1')\n",
        "    x = _batch_norm(x, is_training, 'g_bn1')\n",
        "    x = _relu(x)\n",
        "\n",
        "    x = tf.reshape(x, [-1, 4, 4, 256])\n",
        "\n",
        "    x = _deconv2d(x, 128, 5, 2, 'g_dconv2')\n",
        "    x = _batch_norm(x, is_training, 'g_bn2')\n",
        "    x = _relu(x)\n",
        "    \n",
        "    x = _deconv2d(x, 64, 4, 2, 'g_dconv3')\n",
        "    x = _batch_norm(x, is_training, 'g_bn3')\n",
        "    x = _relu(x)\n",
        "\n",
        "    x = _deconv2d(x, 3, 4, 2, 'g_dconv4')\n",
        "    x = _tanh(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBMcNGEqpBKQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "architectures = {\n",
        "    \"mlpgan\": {\n",
        "        \"generator_fn\": mlpgan_generator_fn,\n",
        "        \"discriminator_fn\": mlpgan_discriminator_fn,\n",
        "        \"generator_loss_fn\": tfgan.losses.modified_generator_loss,\n",
        "        \"discriminator_loss_fn\": tfgan.losses.modified_discriminator_loss,\n",
        "        \"generator_optimizer\": tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        \"discriminator_optimizer\": tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        \"estimator_class\": tfgan.estimator.TPUGANEstimator,\n",
        "        \"noise_dim\": 128\n",
        "    },\n",
        "    \"dcgan\": {\n",
        "        \"generator_fn\": dcgan_generator_fn,\n",
        "        \"discriminator_fn\": dcgan_discriminator_fn,\n",
        "        \"generator_loss_fn\": tfgan.losses.modified_generator_loss,\n",
        "        \"discriminator_loss_fn\": tfgan.losses.modified_discriminator_loss,\n",
        "        \"generator_optimizer\": tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        \"discriminator_optimizer\": tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        \"estimator_class\": tfgan.estimator.TPUGANEstimator,\n",
        "        \"noise_dim\": 128\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XoJiZ_BtqkXF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if ARCHITECTURE not in architectures.keys():\n",
        "  print(\"Architecture {} not found\".format(ARCHITECTURE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FrMG1L2wgrL2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver()\n",
        "master = cluster_resolver.get_master()\n",
        "  \n",
        "model_dir = \"gs://{}/models_dir/{}\".format(BUCKET_NAME, model_name)\n",
        "\n",
        "batches_per_epoch = int(TRAIN_SET_SIZE / TRAIN_BATCH_SIZE)\n",
        "steps_per_epoch = int(batches_per_epoch) * 2\n",
        "iterations_per_loop = int(batches_per_epoch) * 2 # 2 epochs per iteration\n",
        "iterations_steps = iterations_per_loop\n",
        "\n",
        "my_tpu_run_config = tf.contrib.tpu.RunConfig(\n",
        "    master=master,\n",
        "    evaluation_master=master,\n",
        "    model_dir=model_dir,\n",
        "    session_config=tf.ConfigProto(\n",
        "        allow_soft_placement=True,\n",
        "        log_device_placement=True),\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=iterations_per_loop),\n",
        "    save_summary_steps=batches_per_epoch, # save summary every TPU iteration\n",
        "    save_checkpoints_steps=None, # see below\n",
        "    save_checkpoints_secs=3600, # save checkpoints every one hour\n",
        "    keep_checkpoint_max=None        \n",
        ") \n",
        "\n",
        "selected_architecture_config = architectures[ARCHITECTURE]\n",
        "my_gan_estimator = selected_architecture_config['estimator_class'](\n",
        "  generator_fn=selected_architecture_config['generator_fn'],\n",
        "  discriminator_fn=selected_architecture_config['discriminator_fn'],\n",
        "  generator_loss_fn=selected_architecture_config['generator_loss_fn'],\n",
        "  discriminator_loss_fn=selected_architecture_config['discriminator_loss_fn'],\n",
        "  generator_optimizer=selected_architecture_config['generator_optimizer'],\n",
        "  discriminator_optimizer=selected_architecture_config['discriminator_optimizer'],\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  joint_train=False,\n",
        "  config=my_tpu_run_config,\n",
        "  use_tpu=True,\n",
        "  params={\"noise_dim\": selected_architecture_config['noise_dim']},\n",
        "  # EVAL\n",
        "  eval_on_tpu=True,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  # PREDICT\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "91zfqM-Pbhqq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "import itertools\n",
        "from operator import itemgetter\n",
        "from skimage import data, img_as_float\n",
        "from skimage.measure import compare_ssim as ssim\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrZpUEclbTc6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_rows = [np.concatenate(x[i:i+8], axis=0)\n",
        "              for i in range(0, 64, 8)]\n",
        "tiled_image = np.concatenate(image_rows, axis=1)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.imshow(tiled_image)\n",
        "ax.set_title('training set')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yxJhuH-8Yz8t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from_epoch = from_step / 2 / 58\n",
        "\n",
        "generated_iter = my_gan_estimator.predict(input_fn=noise_input_fn,\n",
        "                                          checkpoint_path=os.path.join(model_dir, 'model.ckpt-{}'.format(from_step)))\n",
        "images = [((p['generated_data'][:, :, :] + 1.0) / 2.0) for p in generated_iter]\n",
        "\n",
        "image_rows = [np.concatenate(images[i:i+8], axis=0)\n",
        "              for i in range(0, 64, 8)]\n",
        "tiled_image = np.concatenate(image_rows, axis=1)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.imshow(tiled_image)\n",
        "ax.set_title('{}, epoch: {}'.format(ARCHITECTURE, from_epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2U8zcHOb_kV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "images_new = [np.array(image * 255.0, dtype=np.uint8) for image in images]\n",
        "all_elements = len(images_new) * len(x)\n",
        "cartesian_product = list(itertools.product(images_new, x))\n",
        "\n",
        "x_images_new_sims = []\n",
        "for element in tqdm(np.random.permutation(len(cartesian_product)), total=all_elements):\n",
        "  \n",
        "  similarity = ssim(cartesian_product[element][0], cartesian_product[element][1], multichannel=True) \n",
        "  \n",
        "  if similarity > 0.4:\n",
        "    x_images_new_sims.append((cartesian_product[element][0], cartesian_product[element][1], similarity))\n",
        "    \n",
        "top20 = heapq.nlargest(20, x_images_new_sims, itemgetter(2))\n",
        "\n",
        "image_rows = [np.concatenate([example[0], example[1]], axis=1)\n",
        "              for example in top20]\n",
        "tiled_image = np.concatenate(image_rows, axis=0)\n",
        "\n",
        "dpi = 80\n",
        "shape = tiled_image.shape\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(shape[1]/float(dpi), shape[0]/float(dpi)), dpi=dpi, frameon=False)\n",
        "ax.imshow(tiled_image, extent=(0, 1, 1 ,0), aspect='auto')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.axis('off')\n",
        "fig.subplots_adjust(bottom=0, top=1, left=0, right=1, wspace=0, hspace=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}